# coding=utf-8
# Copyright 2018 The TensorFlow Datasets Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Script to document datasets.

python -m tensorflow_datasets.scripts.document_datasets > docs/datasets.md

"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import collections
import os
import pprint
import sys

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow_datasets.core.utils import py_utils

BASE_URL = "https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets"

# ImageLabelFolder require an extra constructor arg so is handled separately
# TODO(tfds): Document the manual_dir datasets in a separate section
BUILDER_BLACKLIST = ["image_label_folder"]

DOC = """\
<!-- auto-generated by tfds.scripts.document_datasets -->
# Datasets

```
# See all registered datasets
tfds.list_builders()

# Load a given dataset by name
mnist_train_dataset = tfds.load(name="mnist")
```

---

Datasets

{toc}

---

{datasets}
"""

SECTION_DATASETS = """\
# `{section_name}`

{datasets}
"""

CONFIG_BULLET = """\
* `"{name}"` (v{version}): {description}
"""

SINGLE_CONFIG_ENTRY = """\
### `"{builder_name}/{config_name}"`

{feature_information}

"""

DATASET_WITH_CONFIGS_ENTRY = """\
## `"{snakecase_name}"`

{description}

[`{module_and_class}`]({cls_url})

`{snakecase_name}` is configured with `{config_cls}` and has the following
configurations predefined (defaults to the first one):

{config_names}

{configs}

### Statistics
{statistics_information}

### Urls
{urls}

### Supervised Keys
{supervised_keys}

### Citation
```
{citation}
```

---
"""

DATASET_ENTRY = """\
## `"{snakecase_name}"`

{description}

[`{module_and_class}`]({cls_url}) v{version}

### Features
{feature_information}

### Statistics
{statistics_information}

### Urls
{urls}

### Supervised Keys
{supervised_keys}

### Citation
```
{citation}
```

---
"""

FEATURE_TABLE = """\
Name  | Type | Shape
:---- | :--- | :----
{feature_values}
"""

STATISTICS_TABLE = """\
Split  | Examples
:----- | ---:
{split_statistics}
"""


def cls_url(module_name):
  mod_file = sys.modules[module_name].__file__
  if mod_file.endswith("pyc"):
    mod_file = mod_file[:-1]
  path = os.path.relpath(mod_file, py_utils.tfds_dir())
  return os.path.join(BASE_URL, path)


def tfds_mod_name(mod_name):
  parts = mod_name.split(".")
  return ".".join(["tfds"] + parts[1:])


def document_single_builder(builder):
  """Doc string for a single builder, with or without configs."""
  mod_name = builder.__class__.__module__
  cls_name = builder.__class__.__name__
  mod_file = sys.modules[mod_name].__file__
  if mod_file.endswith("pyc"):
    mod_file = mod_file[:-1]

  if builder.builder_configs:
    # Dataset with configs; document each one
    config_docs = []
    for config in builder.BUILDER_CONFIGS:
      builder = tfds.builder(builder.name, config=config)
      info = builder.info
      # TODO(rsepassi): document the actual config object
      config_doc = SINGLE_CONFIG_ENTRY.format(
          builder_name=builder.name,
          config_name=config.name,
          description=config.description,
          version=config.version,
          feature_information=make_feature_information(info),
      )
      config_docs.append(config_doc)
    return DATASET_WITH_CONFIGS_ENTRY.format(
        snakecase_name=builder.name,
        module_and_class="%s.%s" % (tfds_mod_name(mod_name), cls_name),
        cls_url=cls_url(mod_name),
        config_names="\n".join([
            CONFIG_BULLET.format(name=config.name,
                                 description=config.description,
                                 version=config.version)
            for config in builder.BUILDER_CONFIGS]),
        config_cls="%s.%s" % (tfds_mod_name(mod_name),
                              type(builder.builder_config).__name__),
        configs="\n".join(config_docs),
        urls="\n".join([" * " + url for url in info.urls]),
        supervised_keys=str(info.supervised_keys),
        citation=info.citation,
        statistics_information=make_statistics_information(info),
        description=builder.info.description,
    )
  else:
    info = builder.info
    return DATASET_ENTRY.format(
        snakecase_name=builder.name,
        module_and_class="%s.%s" % (tfds_mod_name(mod_name), cls_name),
        cls_url=cls_url(mod_name),
        description=info.description,
        version=info.version,
        feature_information=make_feature_information(info),
        statistics_information=make_statistics_information(info),
        urls="\n".join([" * " + url for url in info.urls]),
        supervised_keys=str(info.supervised_keys),
        citation=info.citation,
    )


def create_section_toc(section, builders):
  heading = "* `%s`" % section
  entry = "  * [`\"{name}\"`](#{name})"
  entries = []
  for builder in builders:
    entries.append(entry.format(name=builder.name))
  return "\n".join([heading] + entries)


def make_module_to_builder_dict():
  """Get all builders organized by module in nested dicts."""
  # pylint: disable=g-long-lambda
  # dict to hold tfds->image->mnist->[builders]
  module_to_builder = collections.defaultdict(
      lambda: collections.defaultdict(
          lambda: collections.defaultdict(list)))
  # pylint: enable=g-long-lambda

  builders = [
      tfds.builder(name)
      for name in tfds.list_builders()
      if name not in BUILDER_BLACKLIST
  ] + [tfds.builder("image_label_folder", dataset_name="image_label_folder")]

  for builder in builders:
    mod_name = builder.__class__.__module__
    modules = mod_name.split(".")

    current_mod_ctr = module_to_builder
    for mod in modules:
      current_mod_ctr = current_mod_ctr[mod]
    current_mod_ctr.append(builder)

  module_to_builder = module_to_builder["tensorflow_datasets"]
  return module_to_builder


def make_feature_information(info):
  """Make feature information table."""
  feature_table_rows = []
  for feature_name in info.features.get_tensor_info():
    try:
      v = info.features[feature_name]
    except KeyError:
      # TODO(afrozm): For things like CelebA's nested attributes this doesn't
      # work, ex: attributes/High_Cheekbones but maybe this is for the better
      # there are O(100)s of attributes if not more.
      continue
    # If we have nested structures we have to do something special.
    v_dtype_str = repr(v.dtype)
    v_shape_str = str(v.shape)
    if isinstance(v.dtype, dict) and isinstance(v.shape, dict):
      # If v.dtype is dict, so must v.shape be.
      v_dtype_str = pprint.pformat(v.dtype, width=1).replace("\n", "<br>")
      v_shape_str = pprint.pformat(v.shape, width=1).replace("\n", "<br>")
    feature_table_rows.append(
        "|".join([feature_name, v_dtype_str, v_shape_str]))
  # We sort the table rows to minimize churn on subsequent generations.
  return FEATURE_TABLE.format(
      feature_values="\n".join(sorted(feature_table_rows)))


def make_statistics_information(info):
  """Make statistics information table."""
  if not info.num_examples:
    # That means that we have yet to calculate the statistics for this.
    return "None computed"

  stats = [(info.num_examples, "ALL")]
  for split_name, split_info in info.splits.items():
    stats.append((split_info.num_examples, split_name.upper()))
  # Sort reverse on number of examples.
  stats.sort(reverse=True)
  stats = "\n".join([
      "{0:10} | {1:>10,}".format(name, num_exs) for (num_exs, name) in stats
  ])
  return STATISTICS_TABLE.format(split_statistics=stats)


def dataset_docs_str():
  """Create dataset documentation string."""
  module_to_builder = make_module_to_builder_dict()

  sections = sorted(list(module_to_builder.keys()))
  section_tocs = []
  section_docs = []
  for section in sections:
    builders = tf.contrib.framework.nest.flatten(module_to_builder[section])
    builders = sorted(builders, key=lambda b: b.name)
    builder_docs = [document_single_builder(builder) for builder in builders]
    section_doc = SECTION_DATASETS.format(
        section_name=section, datasets="\n".join(builder_docs))
    section_docs.append(section_doc)
    section_tocs.append(create_section_toc(section, builders))

  full_doc = DOC.format(toc="\n".join(section_tocs),
                        datasets="\n".join(section_docs))
  return full_doc


if __name__ == "__main__":
  print(dataset_docs_str())
