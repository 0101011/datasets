<!-- auto-generated by tfds.scripts.document_datasets -->
# Datasets

```
# See all registered datasets
tfds.list_builders()

# Load a given dataset by name
mnist_train_dataset = tfds.load(name="mnist")
```

---

Datasets

* `image`
  * [`"celeb_a"`](#celeb_a)
  * [`"cifar10"`](#cifar10)
  * [`"cifar100"`](#cifar100)
  * [`"diabetic_retinopathy_detection"`](#diabetic_retinopathy_detection)
  * [`"fashion_mnist"`](#fashion_mnist)
  * [`"image_label_folder"`](#image_label_folder)
  * [`"mnist"`](#mnist)
  * [`"svhn_cropped"`](#svhn_cropped)
* `text`
  * [`"imdb_reviews"`](#imdb_reviews)
* `video`
  * [`"bair_robot_pushing_small"`](#bair_robot_pushing_small)

---

# `image`

## `"celeb_a"`

From http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html

Large-scale CelebFaces Attributes, CelebA.Set of ~30k celebrities pictures. These pictures are cropped.

[`tfds.image.celeba.CelebA`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/celeba.py) v0.2.0

### Features
Name  | Type | Shape
:---- | :--- | :----
attributes|{'5_o_Clock_Shadow': tf.bool,<br> 'Arched_Eyebrows': tf.bool,<br> 'Attractive': tf.bool,<br> 'Bags_Under_Eyes': tf.bool,<br> 'Bald': tf.bool,<br> 'Bangs': tf.bool,<br> 'Big_Lips': tf.bool,<br> 'Big_Nose': tf.bool,<br> 'Black_Hair': tf.bool,<br> 'Blond_Hair': tf.bool,<br> 'Blurry': tf.bool,<br> 'Brown_Hair': tf.bool,<br> 'Bushy_Eyebrows': tf.bool,<br> 'Chubby': tf.bool,<br> 'Double_Chin': tf.bool,<br> 'Eyeglasses': tf.bool,<br> 'Goatee': tf.bool,<br> 'Gray_Hair': tf.bool,<br> 'Heavy_Makeup': tf.bool,<br> 'High_Cheekbones': tf.bool,<br> 'Male': tf.bool,<br> 'Mouth_Slightly_Open': tf.bool,<br> 'Mustache': tf.bool,<br> 'Narrow_Eyes': tf.bool,<br> 'No_Beard': tf.bool,<br> 'Oval_Face': tf.bool,<br> 'Pale_Skin': tf.bool,<br> 'Pointy_Nose': tf.bool,<br> 'Receding_Hairline': tf.bool,<br> 'Rosy_Cheeks': tf.bool,<br> 'Sideburns': tf.bool,<br> 'Smiling': tf.bool,<br> 'Straight_Hair': tf.bool,<br> 'Wavy_Hair': tf.bool,<br> 'Wearing_Earrings': tf.bool,<br> 'Wearing_Hat': tf.bool,<br> 'Wearing_Lipstick': tf.bool,<br> 'Wearing_Necklace': tf.bool,<br> 'Wearing_Necktie': tf.bool,<br> 'Young': tf.bool}|{'5_o_Clock_Shadow': (),<br> 'Arched_Eyebrows': (),<br> 'Attractive': (),<br> 'Bags_Under_Eyes': (),<br> 'Bald': (),<br> 'Bangs': (),<br> 'Big_Lips': (),<br> 'Big_Nose': (),<br> 'Black_Hair': (),<br> 'Blond_Hair': (),<br> 'Blurry': (),<br> 'Brown_Hair': (),<br> 'Bushy_Eyebrows': (),<br> 'Chubby': (),<br> 'Double_Chin': (),<br> 'Eyeglasses': (),<br> 'Goatee': (),<br> 'Gray_Hair': (),<br> 'Heavy_Makeup': (),<br> 'High_Cheekbones': (),<br> 'Male': (),<br> 'Mouth_Slightly_Open': (),<br> 'Mustache': (),<br> 'Narrow_Eyes': (),<br> 'No_Beard': (),<br> 'Oval_Face': (),<br> 'Pale_Skin': (),<br> 'Pointy_Nose': (),<br> 'Receding_Hairline': (),<br> 'Rosy_Cheeks': (),<br> 'Sideburns': (),<br> 'Smiling': (),<br> 'Straight_Hair': (),<br> 'Wavy_Hair': (),<br> 'Wearing_Earrings': (),<br> 'Wearing_Hat': (),<br> 'Wearing_Lipstick': (),<br> 'Wearing_Necklace': (),<br> 'Wearing_Necktie': (),<br> 'Young': ()}
image|tf.uint8|(218, 178, 3)
landmarks|{'lefteye_x': tf.int64,<br> 'lefteye_y': tf.int64,<br> 'leftmouth_x': tf.int64,<br> 'leftmouth_y': tf.int64,<br> 'nose_x': tf.int64,<br> 'nose_y': tf.int64,<br> 'righteye_x': tf.int64,<br> 'righteye_y': tf.int64,<br> 'rightmouth_x': tf.int64,<br> 'rightmouth_y': tf.int64}|{'lefteye_x': (),<br> 'lefteye_y': (),<br> 'leftmouth_x': (),<br> 'leftmouth_y': (),<br> 'nose_x': (),<br> 'nose_y': (),<br> 'righteye_x': (),<br> 'righteye_y': (),<br> 'rightmouth_x': (),<br> 'rightmouth_y': ()}


### Statistics
Split  | Examples
:----- | ---:
ALL        |    202,599
TRAIN      |    162,770
TEST       |     19,962
VALIDATION |     19,867


### Urls
 * http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html

### Supervised Keys
None

### Citation
```
@inproceedings{conf/iccv/LiuLWT15,
  added-at = {2018-10-09T00:00:00.000+0200},
  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  biburl = {https://www.bibsonomy.org/bibtex/250e4959be61db325d2f02c1d8cd7bfbb/dblp},
  booktitle = {ICCV},
  crossref = {conf/iccv/2015},
  ee = {http://doi.ieeecomputersociety.org/10.1109/ICCV.2015.425},
  interhash = {3f735aaa11957e73914bbe2ca9d5e702},
  intrahash = {50e4959be61db325d2f02c1d8cd7bfbb},
  isbn = {978-1-4673-8391-2},
  keywords = {dblp},
  pages = {3730-3738},
  publisher = {IEEE Computer Society},
  timestamp = {2018-10-11T11:43:28.000+0200},
  title = {Deep Learning Face Attributes in the Wild.},
  url = {http://dblp.uni-trier.de/db/conf/iccv/iccv2015.html#LiuLWT15},
  year = 2015
}

```

---

## `"cifar10"`

From https://www.cs.toronto.edu/~kriz/cifar.html

The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.

[`tfds.image.cifar.Cifar10`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/cifar.py) v1.0.1

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(32, 32, 3)
label|tf.int64|()


### Statistics
Split  | Examples
:----- | ---:
ALL        |     60,000
TRAIN      |     50,000
TEST       |     10,000


### Urls
 * https://www.cs.toronto.edu/~kriz/cifar.html

### Supervised Keys
(u'image', u'label')

### Citation
```
@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

```

---

## `"cifar100"`

From https://www.cs.toronto.edu/~kriz/cifar.html

This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a "fine" label (the class to which it belongs) and a "coarse" label (the superclass to which it belongs).

[`tfds.image.cifar.Cifar100`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/cifar.py) v1.1.0

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(32, 32, 3)
label|tf.int64|()


### Statistics
Split  | Examples
:----- | ---:
ALL        |     60,000
TRAIN      |     50,000
TEST       |     10,000


### Urls
 * https://www.cs.toronto.edu/~kriz/cifar.html

### Supervised Keys
(u'image', u'label')

### Citation
```
@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

```

---

## `"diabetic_retinopathy_detection"`

From https://www.kaggle.com/c/diabetic-retinopathy-detection/data

A large set of high-resolution retina images taken under a variety of imaging conditions.

[`tfds.image.diabetic_retinopathy_detection.DiabeticRetinopathyDetection`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/diabetic_retinopathy_detection.py) v1.0.0

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(None, None, 3)
label|tf.int64|()
name|tf.string|()


### Statistics
Split  | Examples
:----- | ---:
ALL        |     88,712
TEST       |     53,576
TRAIN      |     35,126
SAMPLE     |         10


### Urls
 * https://www.kaggle.com/c/diabetic-retinopathy-detection/data

### Supervised Keys
None

### Citation
```

```

---

## `"fashion_mnist"`

From https://github.com/zalandoresearch/fashion-mnist

Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.

[`tfds.image.mnist.FashionMNIST`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/mnist.py) v1.0.0

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(28, 28, 1)
label|tf.int64|()


### Statistics
Split  | Examples
:----- | ---:
ALL        |     70,000
TRAIN      |     60,000
TEST       |     10,000


### Urls
 * https://github.com/zalandoresearch/fashion-mnist

### Supervised Keys
(u'image', u'label')

### Citation
```
@article{journals/corr/abs-1708-07747,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  biburl = {https://www.bibsonomy.org/bibtex/2c1bcf55a1de644db3d7b0a4a9b7a778e/dblp},
  ee = {http://arxiv.org/abs/1708.07747},
  interhash = {0c81f9a6170118f14703b6796101ce40},
  intrahash = {c1bcf55a1de644db3d7b0a4a9b7a778e},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:22:49.000+0200},
  title = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1708.html#abs-1708-07747},
  volume = {abs/1708.07747},
  year = 2017
}

```

---

## `"image_label_folder"`

From <no known url>

Generic image classification dataset.

[`tfds.image.image_folder.ImageLabelFolder`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/image_folder.py) v1.0.0

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(None, None, 3)
label|tf.int64|()


### Statistics
None computed

### Urls


### Supervised Keys
(u'image', u'label')

### Citation
```

```

---

## `"mnist"`

From http://yann.lecun.com/exdb/mnist/

The MNIST database of handwritten digits.

[`tfds.image.mnist.MNIST`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/mnist.py) v1.0.0

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(28, 28, 1)
label|tf.int64|()


### Statistics
Split  | Examples
:----- | ---:
ALL        |     70,000
TRAIN      |     60,000
TEST       |     10,000


### Urls
 * http://yann.lecun.com/exdb/mnist/

### Supervised Keys
(u'image', u'label')

### Citation
```
@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

```

---

## `"svhn_cropped"`

From http://ufldl.stanford.edu/housenumbers/

The Street View House Numbers (SVHN) Dataset is an image digit recognition dataset of over 600,000 digit images coming from real world data. Images are cropped to 32x32.

[`tfds.image.svhn.SvhnCropped`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/image/svhn.py) v1.0.0

### Features
Name  | Type | Shape
:---- | :--- | :----
image|tf.uint8|(32, 32, 3)
label|tf.int64|()


### Statistics
Split  | Examples
:----- | ---:
ALL        |    630,420
EXTRA      |    531,131
TRAIN      |     73,257
TEST       |     26,032


### Urls
 * http://ufldl.stanford.edu/housenumbers/

### Supervised Keys
(u'image', u'label')

### Citation
```
@article{Netzer2011,
author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
booktitle = {Advances in Neural Information Processing Systems ({NIPS})},
title = {Reading Digits in Natural Images with Unsupervised Feature Learning},
year = {2011}
}

```

---


# `text`

## `"imdb_reviews"`

From http://ai.stanford.edu/~amaas/data/sentiment/

Large Movie Review Dataset.
This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing.

[`tfds.text.imdb.IMDBReviews`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/text/imdb.py)

`imdb_reviews` is configured with `tfds.text.imdb.IMDBReviewsConfig` and has the following
configurations predefined (defaults to the first one):

* `"plain_text"` (v0.0.1): Plain text

* `"bytes"` (v0.0.1): Uses byte-level text encoding with `tfds.features.text.ByteTextEncoder`

* `"subwords8k"` (v0.0.1): Uses `tfds.features.text.SubwordTextEncoder` with 8k vocab size

* `"subwords32k"` (v0.0.1): Uses `tfds.features.text.SubwordTextEncoder` with 32k vocab size


### `"imdb_reviews/plain_text"`

Name  | Type | Shape
:---- | :--- | :----
label|tf.int64|()
text|tf.string|()



### `"imdb_reviews/bytes"`

Name  | Type | Shape
:---- | :--- | :----
label|tf.int64|()
text|tf.int64|(None,)



### `"imdb_reviews/subwords8k"`

Name  | Type | Shape
:---- | :--- | :----
label|tf.int64|()
text|tf.int64|(None,)



### `"imdb_reviews/subwords32k"`

Name  | Type | Shape
:---- | :--- | :----
label|tf.int64|()
text|tf.int64|(None,)




### Statistics
Split  | Examples
:----- | ---:
ALL        |     50,000
TRAIN      |     25,000
TEST       |     25,000


### Urls
 * http://ai.stanford.edu/~amaas/data/sentiment/

### Supervised Keys
(u'text', u'label')

### Citation
```
@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

```

---


# `video`

## `"bair_robot_pushing_small"`

From https://sites.google.com/site/brainrobotdata/home/push-dataset

This data set contains roughly 59,000 examples of robot pushing motions, including one training set (train) and two test sets of previously seen (testseen) and unseen (testnovel) objects. This is the small 64x64 version.

[`tfds.video.bair_robot_pushing.BairRobotPushingSmall`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/video/bair_robot_pushing.py) v1.0.0

### Features
Name  | Type | Shape
:---- | :--- | :----
action|tf.float32|(4,)
endeffector_pos|tf.float32|(3,)
image_aux1|tf.uint8|(64, 64, 3)
image_main|tf.uint8|(64, 64, 3)


### Statistics
Split  | Examples
:----- | ---:
ALL        |     43,520
TRAIN      |     43,264
TEST       |        256


### Urls
 * https://sites.google.com/site/brainrobotdata/home/push-dataset

### Supervised Keys
None

### Citation
```
@inproceedings{conf/nips/FinnGL16,
  added-at = {2016-12-16T00:00:00.000+0100},
  author = {Finn, Chelsea and Goodfellow, Ian J. and Levine, Sergey},
  biburl = {https://www.bibsonomy.org/bibtex/230073873b4fe43b314724b772d0f9256/dblp},
  booktitle = {NIPS},
  crossref = {conf/nips/2016},
  editor = {Lee, Daniel D. and Sugiyama, Masashi and Luxburg, Ulrike V. and Guyon, Isabelle and Garnett, Roman},
  ee = {http://papers.nips.cc/paper/6161-unsupervised-learning-for-physical-interaction-through-video-prediction},
  interhash = {2e6b416723704f4aa5ad0686ce5a3593},
  intrahash = {30073873b4fe43b314724b772d0f9256},
  keywords = {dblp},
  pages = {64-72},
  timestamp = {2016-12-17T11:33:40.000+0100},
  title = {Unsupervised Learning for Physical Interaction through Video Prediction.},
  url = {http://dblp.uni-trier.de/db/conf/nips/nips2016.html#FinnGL16},
  year = 2016
}

```

---


